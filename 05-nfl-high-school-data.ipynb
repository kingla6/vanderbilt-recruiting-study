{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05-nfl-high-school-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Data scraping for all NFL players (appeared in a game) since beginning of league"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook scrapes PFR data for all players and the high schools which they attended in the NFL dating back to 1920 (wow!). This data will be used for analysis comparing recruit counts and location density to NFL talent counts and location density. This code takes a few hours to run if all states are included. In the future, multiprocessing will be added as an ehancement to improve scraping time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant packages\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import janitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function to scrape each state for list of schools, input is list of state abbreviations\n",
    "def state_school(state_list):\n",
    "    \n",
    "    #initialize empty dataframe\n",
    "    all_school_df = pd.DataFrame(columns = ['hs_link', 'hs_name', 'hs_city', 'hs_state', 'num_players', 'num_active'])\n",
    "    \n",
    "    #iterate over each state in the list of states provided\n",
    "    for state in state_list:\n",
    "        \n",
    "        #set the relevant url, must do in parts then join together\n",
    "        url_parts = ['https://www.pro-football-reference.com/schools/high_schools.cgi?hs_state=', str(state)]\n",
    "        url = ''.join(url_parts)\n",
    "        #use get to access the url and save the page\n",
    "        page = rq.get(url)\n",
    "        #save the html content of the page\n",
    "        soup = bs(page.content, 'html.parser')\n",
    "        \n",
    "        #initialize empty lists for scraped data to be stored\n",
    "        school_link = []\n",
    "        school_name = []\n",
    "        school_attributes = [[] for i in range(2)]\n",
    "\n",
    "        #grab the school data from the html content\n",
    "        for school in soup.find_all('th', class_ = 'left'):\n",
    "            school_link.append(school.find('a')['href'])\n",
    "            school_name.append(school.find('a').get_text())\n",
    "\n",
    "        #grab the school data from the html content\n",
    "        for school in soup.find_all('td'):\n",
    "            school_attributes[0].append(school.get('data-stat'))\n",
    "            school_attributes[1].append(school.get_text())\n",
    "\n",
    "        #initialize empty dataframe to store data\n",
    "        school_df = pd.DataFrame({\n",
    "            'hs_link': school_link,\n",
    "            'hs_name': school_name\n",
    "        })\n",
    "\n",
    "        #initialize empty dataframe to store data\n",
    "        attributes_df = pd.DataFrame({\n",
    "            'attribute': school_attributes[0],\n",
    "            'value': school_attributes[1]\n",
    "        })\n",
    "\n",
    "        #split attributes data into individual columns to be joined to full dataframe\n",
    "        hs_city = attributes_df[attributes_df.attribute == 'hs_city'].reset_index(drop = True).rename(columns={'value': 'hs_city'}).drop(['attribute'], axis = 1)\n",
    "        hs_state = attributes_df[attributes_df.attribute == 'hs_state'].reset_index(drop = True).rename(columns={'value': 'hs_state'}).drop(['attribute'], axis = 1)\n",
    "        num_players = attributes_df[attributes_df.attribute == 'num_players'].reset_index(drop = True).rename(columns={'value': 'num_players'}).drop(['attribute'], axis = 1)\n",
    "        num_active = attributes_df[attributes_df.attribute == 'num_active'].reset_index(drop = True).rename(columns={'value': 'num_active'}).drop(['attribute'], axis = 1)\n",
    "        \n",
    "        #concatenate all attributes for schools in the current state\n",
    "        state_school_df = pd.concat([school_df, hs_city, hs_state, num_players, num_active], axis = 1)\n",
    "        \n",
    "        #if there are null values, return this error message\n",
    "        if state_school_df.isnull().values.any() == True:\n",
    "            return('Null values detected in ' + str(state))\n",
    "\n",
    "        #append current state school results to all school list\n",
    "        all_school_df = all_school_df.append(state_school_df, ignore_index = True)\n",
    "    \n",
    "    #return finalized dataframe\n",
    "    return(all_school_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function to scrape each school link for list of players, input is school dataframe from previous function\n",
    "def school_player(schools_df):\n",
    "    \n",
    "    #initialize empty dataframe\n",
    "    all_player_df = pd.DataFrame(columns = ['hs_link', 'player_link', 'player_name', 'pos', 'nfl_team', 'year_min', 'year_max']) \n",
    "    \n",
    "    #iterate over each school link in the list of schools provided\n",
    "    for hs in schools_df.hs_link:\n",
    "        \n",
    "        #set the relevant url, must do in parts then join together\n",
    "        url_parts = ['https://www.pro-football-reference.com/schools/', str(hs)]\n",
    "        url = ''.join(url_parts)\n",
    "        #use get to access the url and save the page\n",
    "        page = rq.get(url)\n",
    "        #save the html content of the page\n",
    "        soup = bs(page.content, 'html.parser')\n",
    "\n",
    "        #initialize empty lists for scraped data to be stored\n",
    "        player_link = []\n",
    "        player_name = []\n",
    "        player_attributes = [[] for i in range(2)]\n",
    "\n",
    "        #grab the player data from the html content\n",
    "        for player in soup.find_all('th', scope = 'row'):\n",
    "            player_link.append(player.find('a')['href'])\n",
    "            player_name.append(player.find('a').get_text())\n",
    "\n",
    "        #grab the player data from the html content\n",
    "        for player in soup.find_all('td'):\n",
    "            player_attributes[0].append(player.get('data-stat'))\n",
    "            player_attributes[1].append(player.get_text())\n",
    "\n",
    "        #initialize empty dataframe to store data\n",
    "        player_df = pd.DataFrame({\n",
    "            'player_link': player_link,\n",
    "            'player_name': player_name\n",
    "        })\n",
    "\n",
    "        #initialize empty dataframe to store data\n",
    "        attributes_df = pd.DataFrame({\n",
    "            'attribute': player_attributes[0],\n",
    "            'value': player_attributes[1]\n",
    "        })\n",
    "\n",
    "        #split attributes data into individual columns to be joined to full dataframe\n",
    "        position = attributes_df[attributes_df.attribute.astype(str) == 'pos'].reset_index(drop = True).rename(columns={'value': 'pos'}).drop(['attribute'], axis = 1)\n",
    "        nfl_team = attributes_df[attributes_df.attribute.astype(str) == 'teams'].reset_index(drop = True).rename(columns={'value': 'nfl_team'}).drop(['attribute'], axis = 1)\n",
    "        year_min = attributes_df[attributes_df.attribute.astype(str) == 'year_min'].reset_index(drop = True).rename(columns={'value': 'year_min'}).drop(['attribute'], axis = 1)\n",
    "        year_max = attributes_df[attributes_df.attribute.astype(str) == 'year_max'].reset_index(drop = True).rename(columns={'value': 'year_max'}).drop(['attribute'], axis = 1)\n",
    "\n",
    "        #concatenate all attributes for players in the current school\n",
    "        school_player_df = pd.concat([player_df, position, nfl_team, year_min, year_max], axis = 1)\n",
    "\n",
    "        #if there are null values, return this error message\n",
    "        if school_player_df.isnull().values.any() == True:\n",
    "            return('Null values detected in ' + str(hs))\n",
    "\n",
    "        #repeat the link of the current school for the length of the school_player_df\n",
    "        hs_link_df = pd.DataFrame(np.repeat(hs, [len(school_player_df)]), columns = ['hs_link'])\n",
    "\n",
    "        #concatenate links and player info, append to large dataframe\n",
    "        all_player_df = all_player_df.append(pd.concat([hs_link_df, school_player_df], axis = 1), ignore_index = True)\n",
    "\n",
    "    #return finalized dataframe    \n",
    "    return(all_player_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#states list to be used in function\n",
    "states = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\", \n",
    "          \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "          \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "          \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "          \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ['AK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run state_school with specified list of states and save\n",
    "all_schools = state_school(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run school_player function on returned dataframe from above cell and save\n",
    "all_players = school_player(all_schools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicated player values (result of one school link being listed twice for separate schools)\n",
    "all_players = all_players[~all_players.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge player and school data (inner join)\n",
    "export = all_schools.merge(all_players, on = 'hs_link')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove observations where the school link is the incorrect one, reset index\n",
    "#drop num_players and num_active because they are often inaccurate\n",
    "export = export[~((export.hs_link == 'high_schools.cgi?id=93bdb950') & (export.hs_state == 'MI'))].reset_index(drop = True).drop(['num_players', 'num_active'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hs_link</th>\n",
       "      <th>hs_name</th>\n",
       "      <th>hs_city</th>\n",
       "      <th>hs_state</th>\n",
       "      <th>player_link</th>\n",
       "      <th>player_name</th>\n",
       "      <th>pos</th>\n",
       "      <th>nfl_team</th>\n",
       "      <th>year_min</th>\n",
       "      <th>year_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high_schools.cgi?id=93b98f93</td>\n",
       "      <td>Lathrop</td>\n",
       "      <td>Fairbanks</td>\n",
       "      <td>AK</td>\n",
       "      <td>/players/T/TongRe20.htm</td>\n",
       "      <td>Reggie Tongue</td>\n",
       "      <td>DB</td>\n",
       "      <td>KAN,SEA,NYJ,OAK</td>\n",
       "      <td>1996</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high_schools.cgi?id=93b98f93</td>\n",
       "      <td>Lathrop</td>\n",
       "      <td>Fairbanks</td>\n",
       "      <td>AK</td>\n",
       "      <td>/players/B/BonhSh20.htm</td>\n",
       "      <td>Shane Bonham</td>\n",
       "      <td>DT</td>\n",
       "      <td>DET,SFO,IND</td>\n",
       "      <td>1994</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high_schools.cgi?id=93c085dc</td>\n",
       "      <td>East Anchorage</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>AK</td>\n",
       "      <td>/players/T/TosiMa20.htm</td>\n",
       "      <td>Mao Tosi</td>\n",
       "      <td>DT-DE</td>\n",
       "      <td>ARI</td>\n",
       "      <td>2000</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high_schools.cgi?id=93bf09cb</td>\n",
       "      <td>Ben Eielson</td>\n",
       "      <td>Fairbanks</td>\n",
       "      <td>AK</td>\n",
       "      <td>/players/N/NeviTo20.htm</td>\n",
       "      <td>Tom Neville</td>\n",
       "      <td>G-T</td>\n",
       "      <td>GNB,SFO</td>\n",
       "      <td>1986</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high_schools.cgi?id=93baf296</td>\n",
       "      <td>North Pole</td>\n",
       "      <td>North Pole</td>\n",
       "      <td>AK</td>\n",
       "      <td>/players/C/CollDa20.htm</td>\n",
       "      <td>Daryn Colledge</td>\n",
       "      <td>T</td>\n",
       "      <td>GNB,ARI,MIA</td>\n",
       "      <td>2006</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>high_schools.cgi?id=2a0de876</td>\n",
       "      <td>Service</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>AK</td>\n",
       "      <td>/players/O/OverJe00.htm</td>\n",
       "      <td>Jeff Overbaugh</td>\n",
       "      <td>LS</td>\n",
       "      <td>MIN,ATL</td>\n",
       "      <td>2017</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>high_schools.cgi?id=93bfe2a9</td>\n",
       "      <td>Robert Service</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>AK</td>\n",
       "      <td>/players/S/SchlMa00.htm</td>\n",
       "      <td>Mark Schlereth</td>\n",
       "      <td>G-C</td>\n",
       "      <td>WAS,DEN</td>\n",
       "      <td>1989</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>high_schools.cgi?id=93bdffc5</td>\n",
       "      <td>A.J. Dimond</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>AK</td>\n",
       "      <td>/players/K/KupeCh20.htm</td>\n",
       "      <td>Chris Kuper</td>\n",
       "      <td>G</td>\n",
       "      <td>DEN</td>\n",
       "      <td>2006</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>high_schools.cgi?id=93b9a334</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>AK</td>\n",
       "      <td>/players/B/BowmZa20.htm</td>\n",
       "      <td>Zackary Bowman</td>\n",
       "      <td>DB</td>\n",
       "      <td>CHI,NYG,MIA</td>\n",
       "      <td>2008</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>high_schools.cgi?id=93bf10ec</td>\n",
       "      <td>Howkan</td>\n",
       "      <td>Howkan</td>\n",
       "      <td>AK</td>\n",
       "      <td>/players/N/NixxGe20.htm</td>\n",
       "      <td>George Nix</td>\n",
       "      <td>G</td>\n",
       "      <td>BUF</td>\n",
       "      <td>1926</td>\n",
       "      <td>1926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>high_schools.cgi?id=93bde676</td>\n",
       "      <td>West Anchorage</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>AK</td>\n",
       "      <td>/players/K/KlevRo00.htm</td>\n",
       "      <td>Rocky Klever</td>\n",
       "      <td>TE-RB</td>\n",
       "      <td>NYJ</td>\n",
       "      <td>1983</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         hs_link         hs_name     hs_city hs_state  \\\n",
       "0   high_schools.cgi?id=93b98f93         Lathrop   Fairbanks       AK   \n",
       "1   high_schools.cgi?id=93b98f93         Lathrop   Fairbanks       AK   \n",
       "2   high_schools.cgi?id=93c085dc  East Anchorage   Anchorage       AK   \n",
       "3   high_schools.cgi?id=93bf09cb     Ben Eielson   Fairbanks       AK   \n",
       "4   high_schools.cgi?id=93baf296      North Pole  North Pole       AK   \n",
       "5   high_schools.cgi?id=2a0de876         Service   Anchorage       AK   \n",
       "6   high_schools.cgi?id=93bfe2a9  Robert Service   Anchorage       AK   \n",
       "7   high_schools.cgi?id=93bdffc5     A.J. Dimond   Anchorage       AK   \n",
       "8   high_schools.cgi?id=93b9a334        Bartlett   Anchorage       AK   \n",
       "9   high_schools.cgi?id=93bf10ec          Howkan      Howkan       AK   \n",
       "10  high_schools.cgi?id=93bde676  West Anchorage   Anchorage       AK   \n",
       "\n",
       "                player_link     player_name    pos         nfl_team year_min  \\\n",
       "0   /players/T/TongRe20.htm   Reggie Tongue     DB  KAN,SEA,NYJ,OAK     1996   \n",
       "1   /players/B/BonhSh20.htm    Shane Bonham     DT      DET,SFO,IND     1994   \n",
       "2   /players/T/TosiMa20.htm        Mao Tosi  DT-DE              ARI     2000   \n",
       "3   /players/N/NeviTo20.htm    Tom Neville     G-T          GNB,SFO     1986   \n",
       "4   /players/C/CollDa20.htm  Daryn Colledge      T      GNB,ARI,MIA     2006   \n",
       "5   /players/O/OverJe00.htm  Jeff Overbaugh     LS          MIN,ATL     2017   \n",
       "6   /players/S/SchlMa00.htm  Mark Schlereth    G-C          WAS,DEN     1989   \n",
       "7   /players/K/KupeCh20.htm     Chris Kuper      G              DEN     2006   \n",
       "8   /players/B/BowmZa20.htm  Zackary Bowman     DB      CHI,NYG,MIA     2008   \n",
       "9   /players/N/NixxGe20.htm      George Nix      G              BUF     1926   \n",
       "10  /players/K/KlevRo00.htm    Rocky Klever  TE-RB              NYJ     1983   \n",
       "\n",
       "   year_max  \n",
       "0      2005  \n",
       "1      1999  \n",
       "2      2001  \n",
       "3      1992  \n",
       "4      2014  \n",
       "5      2018  \n",
       "6      2000  \n",
       "7      2013  \n",
       "8      2015  \n",
       "9      1926  \n",
       "10     1987  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display final data\n",
    "export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "export.to_csv('preliminary-data/all-nfl-player.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
